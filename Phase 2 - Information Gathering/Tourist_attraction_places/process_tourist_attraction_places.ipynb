{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import geopandas as gpd\n",
    "from pprint import pprint\n",
    "from shapely.geometry import Point, LineString, Polygon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geometry_from_overpass(element):\n",
    "    coords = [(coord[\"lon\"], coord[\"lat\"]) for coord in element[\"geometry\"]]\n",
    "\n",
    "    if coords[0] == coords[-1]:\n",
    "        return Polygon(coords)\n",
    "    else:\n",
    "        return LineString(coords)\n",
    "\n",
    "\n",
    "def get_gdf(data_dir):\n",
    "    try:\n",
    "        with open(data_dir, encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "    except:\n",
    "        exception = \"Error: Could not load the file\"\n",
    "        return exception\n",
    "            \n",
    "    features = []\n",
    "\n",
    "    for element in data[\"elements\"]:\n",
    "        el_type = element[\"type\"]\n",
    "        tags = element.get(\"tags\", {})\n",
    "        tags[\"id\"] = element[\"id\"]\n",
    "        element[\"tags\"][\"name\"] = element[\"tags\"].get(\"name\", \"Unnamed\")\n",
    "        element[\"tags\"][\"latitude\"] = element.get(\"lat\", None)\n",
    "        element[\"tags\"][\"longitude\"] = element.get(\"lon\", None)\n",
    "\n",
    "        if el_type in [\"way\", \"relation\"] and \"geometry\" in element:\n",
    "            geom = geometry_from_overpass(element)\n",
    "            features.append({**tags, \"geometry\": geom})\n",
    "\n",
    "        elif el_type == \"node\":\n",
    "            lon = element[\"lon\"]\n",
    "            lat = element[\"lat\"]\n",
    "            geom = Point(lon, lat)\n",
    "            features.append({**tags, \"geometry\": geom})\n",
    "\n",
    "    return gpd.GeoDataFrame(features, crs=\"EPSG:4326\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = get_gdf(\"./raw_data/caves.geojson\")\n",
    "caves_columns = [\"id\", \"name\", \"longitude\",\"latitude\",\"geometry\"]\n",
    "caves_df = gdf[caves_columns]\n",
    "caves_df[:]['type'] = 'cave'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "caves_df.to_csv(\"./processed_data/caves.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cultural Attractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These include\n",
    "* artworks\n",
    "* memorials\n",
    "* Galleries and Museums\n",
    "* Castles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = get_gdf(\"./raw_data/cultural_attractions.geojson\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "artworks_df = gdf[gdf.tourism=='artwork'][['id', 'name', 'latitude', 'longitude','geometry', 'artist_name', 'description', 'source:website','artwork_type']]\n",
    "memorials_df = gdf[gdf.historic.isin(['memorial','monument','castle']) ][['id', 'name', 'latitude', 'longitude','geometry','memorial', 'historic', 'inscription']]\n",
    "gallery_and_museum_df = gdf[gdf.tourism.isin(['gallery','museum'])][['id', 'name', 'latitude', 'longitude','geometry','contact:website','tourism','addr:street','addr:city','addr:postcode','addr:housenumber']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "artworks_df.rename(columns={'artwork_type':'type', 'source:website':'website'}, inplace=True)\n",
    "memorials_df['type'] = memorials_df['historic'] + memorials_df['memorial']\n",
    "memorials_df.rename(columns={'memorial':'memorial_type'}, inplace=True)\n",
    "memorials_df.drop(columns=['historic'], inplace=True)\n",
    "gallery_and_museum_df.rename(columns={'addr:street':'street', 'addr:city':'city', 'addr:postcode':'postcode', 'addr:housenumber':'housenumber', 'contact:website':'website'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "artworks_df.to_csv(\"./processed_data/artworks.csv\", index=False, sep=\";\")\n",
    "memorials_df.to_csv(\"./processed_data/memorials.csv\", index=False, sep=\";\")\n",
    "gallery_and_museum_df.to_csv(\"./processed_data/gallery_and_museums.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Food and Drink Establishments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = get_gdf(\"./raw_data/food_and_drink_establishments.geojson\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_and_drink_establishments_df = gdf[['id','latitude','longitude','geometry','name','cuisine','operator',\n",
    "                                        'addr:street','addr:city','addr:postcode','addr:housenumber',\n",
    "                                        'contact:website','phone','contact:phone','contact:email','website',\n",
    "                                        'amenity'\n",
    "                                        ]].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_and_drink_establishments_df.website.isna().sum(), food_and_drink_establishments_df['contact:website'].isna().sum(), \n",
    "food_and_drink_establishments_df[:]['website'] = food_and_drink_establishments_df['website'].combine_first(food_and_drink_establishments_df['contact:website'])\n",
    "food_and_drink_establishments_df[:]['phone'] = food_and_drink_establishments_df['phone'].combine_first(food_and_drink_establishments_df['contact:phone'])\n",
    "food_and_drink_establishments_df.rename(columns={'addr:street':'street', 'addr:city':'city', 'addr:postcode':'postcode', 'addr:housenumber':'housenumber','amenity':'type','contact:email':'email'}, inplace=True)\n",
    "food_and_drink_establishments_df.drop(columns=['contact:website', 'contact:phone'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_and_drink_establishments_df.to_csv(\"./processed_data/food_and_drink_establishments.csv\", index=False,sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holiday Apartments and Houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = get_gdf(\"./raw_data/holiday_apartments_and_houses.geojson\")\n",
    "\n",
    "holiday_apartments_and_houses_df = gdf[['id','latitude','longitude','geometry','name','addr:street', 'addr:city','addr:postcode','addr:housenumber','contact:website','contact:phone','contact:email','website','phone','email','tourism']].copy(deep=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_apartments_and_houses_df[:]['website'] = holiday_apartments_and_houses_df['website'].combine_first(holiday_apartments_and_houses_df['contact:website'])\n",
    "holiday_apartments_and_houses_df[:]['phone'] = holiday_apartments_and_houses_df['phone'].combine_first(holiday_apartments_and_houses_df['contact:phone'])\n",
    "holiday_apartments_and_houses_df[:]['email'] = holiday_apartments_and_houses_df['email'].combine_first(holiday_apartments_and_houses_df['contact:email'])\n",
    "holiday_apartments_and_houses_df.rename(columns={'addr:street':'street', 'addr:city':'city', 'addr:postcode':'postcode', 'addr:housenumber':'housenumber','tourism':'type'}, inplace=True)\n",
    "\n",
    "holiday_apartments_and_houses_df.drop(columns=['contact:website', 'contact:phone', 'contact:email'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_apartments_and_houses_df.to_csv(\"./processed_data/holiday_apartments_and_houses.csv\", index=False, sep=\";\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hotels and Accomodation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = get_gdf(\"./raw_data/hotels_and_accommodation.geojson\")\n",
    "\n",
    "hotels_and_accommodation_df = gdf[['id','latitude','longitude','geometry','name','tourism',\n",
    "                                   'addr:street', 'addr:city','addr:postcode','addr:housenumber',\n",
    "                                   'cuisine','description','operator',\n",
    "                                   'contact:website','contact:phone','contact:email','website','phone','email']].copy(deep=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels_and_accommodation_df[:]['website'] = hotels_and_accommodation_df['website'].combine_first(hotels_and_accommodation_df['contact:website'])\n",
    "hotels_and_accommodation_df[:]['phone'] = hotels_and_accommodation_df['phone'].combine_first(hotels_and_accommodation_df['contact:phone'])\n",
    "hotels_and_accommodation_df[:]['email'] = hotels_and_accommodation_df['email'].combine_first(hotels_and_accommodation_df['contact:email'])\n",
    "hotels_and_accommodation_df.rename(columns={'addr:street':'street', 'addr:city':'city', 'addr:postcode':'postcode', 'addr:housenumber':'housenumber','tourism':'type'}, inplace=True)\n",
    "\n",
    "hotels_and_accommodation_df.drop(columns=['contact:website', 'contact:phone', 'contact:email'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels_and_accommodation_df.to_csv(\"./processed_data/hotels_and_accommodation.csv\", index=False,sep=\";\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lakes and Rivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./raw_data/lakes_and_rivers.geojson', \"r\") as file:\n",
    "    data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, LineString\n",
    "from shapely import wkt\n",
    "\n",
    "# Load your Overpass JSON data\n",
    "with open('./raw_data/lakes_and_rivers.geojson', \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "# Initialize lists to hold lake and river data\n",
    "lakes = []\n",
    "rivers = []\n",
    "\n",
    "# Process each element in the JSON data\n",
    "for element in data[\"elements\"]:\n",
    "    tags = element.get(\"tags\", {})\n",
    "\n",
    "    # Extract lakes based on 'natural=water' and 'water=lake'\n",
    "    if tags.get(\"natural\") == \"water\" and tags.get(\"water\") == \"lake\":\n",
    "        # For relations, use the center and the geometry from members; otherwise use the element's geometry\n",
    "        if element[\"type\"] == \"relation\":\n",
    "            lat = element.get(\"center\", {}).get(\"lat\")\n",
    "            lon = element.get(\"center\", {}).get(\"lon\")\n",
    "            # We assume the geometry comes from the first member (adjust if needed)\n",
    "            geom_data = element.get(\"members\", [{}])[0].get(\"geometry\", [])\n",
    "        else:\n",
    "            lat = element.get(\"lat\")\n",
    "            lon = element.get(\"lon\")\n",
    "            geom_data = element.get(\"geometry\", [])\n",
    "        \n",
    "        wkt_geom = None\n",
    "        if isinstance(geom_data, list) and len(geom_data) >= 3:\n",
    "            # Convert coordinate dictionaries to (lon, lat) tuples\n",
    "            coords = [(pt[\"lon\"], pt[\"lat\"]) for pt in geom_data]\n",
    "            # Ensure the polygon is closed by checking if the first and last coordinate are the same.\n",
    "            if coords[0] != coords[-1]:\n",
    "                coords.append(coords[0])\n",
    "            try:\n",
    "                poly = Polygon(coords)\n",
    "                wkt_geom = poly.wkt  # WKT literal of the polygon\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating polygon for lake element {element['id']}: {e}\")\n",
    "        \n",
    "        lakes.append({\n",
    "            \"id\": element[\"id\"],\n",
    "            \"name\": tags.get(\"name\", \"Unnamed\"),\n",
    "            \"latitude\": lat,\n",
    "            \"longitude\": lon,\n",
    "            \"bounds\": element.get(\"bounds\", ''),\n",
    "            \"geometry\": wkt_geom,\n",
    "            \"type\": \"lake\",\n",
    "        })\n",
    "        \n",
    "    # Extract rivers based on 'waterway=river'\n",
    "    elif tags.get(\"waterway\") == \"river\":\n",
    "        geom_data = element.get(\"geometry\", [])\n",
    "        wkt_geom = None\n",
    "        # For a river, even if there are only 2 coordinates, we can create a LineString\n",
    "        if isinstance(geom_data, list) and len(geom_data) >= 2:\n",
    "            coords = [(pt[\"lon\"], pt[\"lat\"]) for pt in geom_data]\n",
    "            try:\n",
    "                line = LineString(coords)\n",
    "                wkt_geom = line.wkt  # WKT literal of the linestring\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating LineString for river element {element['id']}: {e}\")\n",
    "        \n",
    "        rivers.append({\n",
    "            \"id\": element[\"id\"],\n",
    "            \"name\": tags.get(\"name\", \"Unnamed\"),\n",
    "            \"latitude\": element.get(\"center\", {}).get(\"lat\"),\n",
    "            \"longitude\": element.get(\"center\", {}).get(\"lon\"),\n",
    "            \"bounds\": element.get(\"bounds\", ''),\n",
    "            \"geometry\": wkt_geom,\n",
    "            \"type\": \"river\",\n",
    "        })\n",
    "# Create DataFrames for lakes and rivers\n",
    "lakes_df = pd.DataFrame(lakes)\n",
    "rivers_df = pd.DataFrame(rivers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "lakes_df.dropna(axis=0, subset=['geometry'], inplace=True)\n",
    "rivers_df.dropna(axis=0, subset=['geometry'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the DataFrames to CSV (the \"geometry\" column contains the WKT literal)\n",
    "lakes_df.to_csv(\"./processed_data/lakes.csv\", index=False, sep=\";\")\n",
    "rivers_df.to_csv(\"./processed_data/rivers.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./raw_data/beaches.geojson', \"r\") as file:\n",
    "    data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'access',\n",
       " 'created_by',\n",
       " 'description',\n",
       " 'dog',\n",
       " 'leisure',\n",
       " 'lifeguard',\n",
       " 'name',\n",
       " 'natural',\n",
       " 'sport',\n",
       " 'supervised',\n",
       " 'surface'}"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_items = {tag for element in data[\"elements\"] for tag in element.get(\"tags\", {})}\n",
    "tag_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to hold lake and river data\n",
    "beach = []\n",
    "\n",
    "# Process each element in the JSON data\n",
    "for element in data[\"elements\"]:\n",
    "    tags = element.get(\"tags\", {})\n",
    "    # Extract beaches based on 'natural=beach' \n",
    "    if tags.get(\"natural\") == \"beach\":\n",
    "        if element[\"type\"] == \"node\":\n",
    "            beach.append({\n",
    "                \"id\": \"beach_id_\"+str(element[\"id\"]),\n",
    "                \"name\": tags.get(\"name\", \"Unnamed\"),\n",
    "                \"latitude\": element.get(\"lat\"),\n",
    "                \"longitude\": element.get(\"lon\"),\n",
    "                \"bounds\": element.get(\"bounds\", ''),\n",
    "                \"geometry\": element.get(\"geometry\", 'POINT (' + str( element['center'][\"lon\"]) + ' ' + str( element['center'][\"lat\"]) + ')' ),\n",
    "                \"type\": tags.get(\"natural\", \"beach\")+(':'+tags.get(\"surface\", \"\")) if tags.get(\"surface\") else 'beach',\n",
    "            })\n",
    "        else:\n",
    "            beach.append({\n",
    "                \"id\": \"beach_id_\"+str(element[\"id\"]),\n",
    "                \"name\": tags.get(\"name\", \"Unnamed\"),\n",
    "                \"latitude\": element.get(\"lat\"),\n",
    "                \"longitude\": element.get(\"lon\"),\n",
    "                \"bounds\": element.get(\"bounds\", ''),\n",
    "                \"geometry\": element.get(\"geometry\", 'POINT (' + str( element['center'][\"lon\"]) + ' ' + str( element['center'][\"lat\"]) + ')' ),\n",
    "                \"type\": tags.get(\"natural\", \"beach\")+(':'+tags.get(\"surface\", \"\")) if tags.get(\"surface\") else 'beach',\n",
    "                \n",
    "            })\n",
    "    \n",
    "\n",
    "# Create DataFrames for beach\n",
    "beach_df = pd.DataFrame(beach)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON data\n",
    "with open('./raw_data/beaches.geojson', \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize list for beaches\n",
    "beach = []\n",
    "\n",
    "# Process each element in the JSON data\n",
    "for element in data[\"elements\"]:\n",
    "    tags = element.get(\"tags\", {})\n",
    "\n",
    "    # Extract beaches based on 'natural=beach'\n",
    "    if tags.get(\"natural\") == \"beach\":\n",
    "        geometry_wkt = None  # Default empty geometry\n",
    "\n",
    "        if element[\"type\"] == \"node\":\n",
    "            # Nodes: Use a Point\n",
    "            lat = element.get(\"lat\")\n",
    "            lon = element.get(\"lon\")\n",
    "            if lat and lon:\n",
    "                geometry_wkt = Point(lon, lat).wkt\n",
    "\n",
    "        elif element[\"type\"] in [\"way\", \"relation\"]:\n",
    "            # Ways/Relations: Convert geometry list to Polygon (or LineString)\n",
    "            geom_data = element.get(\"geometry\", [])\n",
    "            if isinstance(geom_data, list) and len(geom_data) >= 3:\n",
    "                coords = [(pt[\"lon\"], pt[\"lat\"]) for pt in geom_data]\n",
    "                # Ensure it forms a closed polygon\n",
    "                if coords[0] != coords[-1]:\n",
    "                    coords.append(coords[0])\n",
    "                try:\n",
    "                    geometry_wkt = Polygon(coords).wkt  # Polygon WKT\n",
    "                except Exception as e:\n",
    "                    print(f\"Error creating polygon for beach {element['id']}: {e}\")\n",
    "\n",
    "            elif isinstance(geom_data, list) and len(geom_data) >= 2:\n",
    "                # If not enough points for a polygon, store as LineString\n",
    "                coords = [(pt[\"lon\"], pt[\"lat\"]) for pt in geom_data]\n",
    "                try:\n",
    "                    geometry_wkt = LineString(coords).wkt  # LineString WKT\n",
    "                except Exception as e:\n",
    "                    print(f\"Error creating linestring for beach {element['id']}: {e}\")\n",
    "\n",
    "        # Append data to beach list\n",
    "        beach.append({\n",
    "            \"id\": f\"beach_id_{element['id']}\",\n",
    "            \"name\": tags.get(\"name\", \"Unnamed\"),\n",
    "            \"latitude\": element.get(\"lat\") if element[\"type\"] == \"node\" else None,\n",
    "            \"longitude\": element.get(\"lon\") if element[\"type\"] == \"node\" else None,\n",
    "            \"bounds\": element.get(\"bounds\", ''),\n",
    "            \"geometry\": geometry_wkt,  # Store WKT format\n",
    "            \"type\": tags.get(\"natural\", \"beach\") + (\":\" + tags.get(\"surface\", \"\")) if tags.get(\"surface\") else \"beach\",\n",
    "        })\n",
    "\n",
    "# Create a DataFrame\n",
    "beach_df = pd.DataFrame(beach)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save to CSV\n",
    "beach_df.to_csv(\"./processed_data/beaches.csv\", index=False, sep=\";\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peaks and Viewpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = get_gdf(\"./raw_data/peaks_and_viewpoints.geojson\")\n",
    "\n",
    "\n",
    "peaks_and_viewpoints_df = gdf[[\"id\", \"name\", \"longitude\",\"latitude\",\"geometry\", \"description\",\"historic\", \"amenity\",\"height\",\"website\",\"natural\" ]].copy(deep=True)\n",
    "peaks_and_viewpoints_df.rename(columns={'natural':'type'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_and_viewpoints_df.to_csv(\"./processed_data/peaks_and_viewpoints.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protected Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./raw_data/protected_areas.geojson', \"r\") as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "protected_areas = []\n",
    "\n",
    "\n",
    "for element in data[\"elements\"]:\n",
    "    tags = element.get(\"tags\", {})\n",
    "    protected_areas.append({\n",
    "        \"id\": \"PA_id_\"+ str(element[\"id\"]),\n",
    "        \"latitude\": element['center'][\"lat\"],\n",
    "        \"longitude\": element['center'][\"lon\"],\n",
    "        \"geometry\": element.get(\"geometry\", 'POINT (' + str( element['center'][\"lon\"]) + ' ' + str( element['center'][\"lat\"]) + ')' ),\n",
    "        \"name\": tags.get(\"name\"),\n",
    "        \"source\": tags.get(\"source\"),\n",
    "        \"website\": tags.get(\"website\"),\n",
    "        \"protection_title\": tags.get(\"protection_title\"),\n",
    "        \"leisure\": tags.get(\"leisure\"),\n",
    "        \"type\":'protected area'\n",
    "        \n",
    "    })\n",
    "    \n",
    "    \n",
    "protected_areas_df = pd.DataFrame(protected_areas)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>geometry</th>\n",
       "      <th>name</th>\n",
       "      <th>source</th>\n",
       "      <th>website</th>\n",
       "      <th>protection_title</th>\n",
       "      <th>leisure</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PA_id_4710461</td>\n",
       "      <td>45.884332</td>\n",
       "      <td>10.692263</td>\n",
       "      <td>POINT (10.6922633 45.8843322)</td>\n",
       "      <td>Rete di riserve Alpi Ledrensi</td>\n",
       "      <td>Provincia autonoma di Trento</td>\n",
       "      <td>https://www.reteriservealpiledrensi.tn.it/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>protected area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PA_id_15595792</td>\n",
       "      <td>46.490497</td>\n",
       "      <td>11.586921</td>\n",
       "      <td>POINT (11.586921 46.4904972)</td>\n",
       "      <td>Naturpark Schlern-Rosengarten – Parco naturale...</td>\n",
       "      <td>EEA CDDA (v20)</td>\n",
       "      <td>https://parchi-naturali.provincia.bz.it/parco-...</td>\n",
       "      <td>Parco naturale</td>\n",
       "      <td>nature_reserve</td>\n",
       "      <td>protected area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PA_id_15638582</td>\n",
       "      <td>46.536940</td>\n",
       "      <td>11.668578</td>\n",
       "      <td>POINT (11.668578 46.5369404)</td>\n",
       "      <td>Landschaftsschutzgebiet Seiser Alm – Zona di T...</td>\n",
       "      <td>\"Piani paesaggistici: Delimitazioni dei Piani ...</td>\n",
       "      <td>https://seiseralm-schlerngebiet.com/seiseralm/...</td>\n",
       "      <td>Zona di Tutela Paesaggistica</td>\n",
       "      <td>None</td>\n",
       "      <td>protected area</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id   latitude  longitude                       geometry  \\\n",
       "0   PA_id_4710461  45.884332  10.692263  POINT (10.6922633 45.8843322)   \n",
       "1  PA_id_15595792  46.490497  11.586921   POINT (11.586921 46.4904972)   \n",
       "2  PA_id_15638582  46.536940  11.668578   POINT (11.668578 46.5369404)   \n",
       "\n",
       "                                                name  \\\n",
       "0                      Rete di riserve Alpi Ledrensi   \n",
       "1  Naturpark Schlern-Rosengarten – Parco naturale...   \n",
       "2  Landschaftsschutzgebiet Seiser Alm – Zona di T...   \n",
       "\n",
       "                                              source  \\\n",
       "0                       Provincia autonoma di Trento   \n",
       "1                                     EEA CDDA (v20)   \n",
       "2  \"Piani paesaggistici: Delimitazioni dei Piani ...   \n",
       "\n",
       "                                             website  \\\n",
       "0         https://www.reteriservealpiledrensi.tn.it/   \n",
       "1  https://parchi-naturali.provincia.bz.it/parco-...   \n",
       "2  https://seiseralm-schlerngebiet.com/seiseralm/...   \n",
       "\n",
       "               protection_title         leisure            type  \n",
       "0                          None            None  protected area  \n",
       "1                Parco naturale  nature_reserve  protected area  \n",
       "2  Zona di Tutela Paesaggistica            None  protected area  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protected_areas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_areas_df.to_csv(\"./processed_data/protected_areas.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skiing and Winter Sports facility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./raw_data/skiing_and_winter_sports.geojson', \"r\") as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, LineString\n",
    "from shapely import wkt\n",
    "\n",
    "# Load JSON data\n",
    "with open('./raw_data/skiing_and_winter_sports.geojson', \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize list for skiing & piste areas\n",
    "sna = []\n",
    "\n",
    "# Process each element in the JSON data\n",
    "for element in data[\"elements\"]:\n",
    "    tags = element.get(\"tags\", {}).copy()  # Copy tags to avoid modifying original\n",
    "\n",
    "    geometry_wkt = None  # Default empty geometry\n",
    "\n",
    "    if element[\"type\"] == \"node\":\n",
    "        # Nodes: Represented as Points\n",
    "        lat = element.get(\"lat\")\n",
    "        lon = element.get(\"lon\")\n",
    "        if lat and lon:\n",
    "            geometry_wkt = Point(lon, lat).wkt\n",
    "\n",
    "    elif element[\"type\"] in [\"way\", \"relation\"]:\n",
    "        # Ways/Relations: Convert geometry list to Polygon (or LineString)\n",
    "        geom_data = element.get(\"geometry\", [])\n",
    "        if isinstance(geom_data, list) and len(geom_data) >= 3:\n",
    "            coords = [(pt[\"lon\"], pt[\"lat\"]) for pt in geom_data]\n",
    "            # Ensure it forms a closed polygon\n",
    "            if coords[0] != coords[-1]:\n",
    "                coords.append(coords[0])\n",
    "            try:\n",
    "                geometry_wkt = Polygon(coords).wkt  # Polygon WKT\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating polygon for SNA {element['id']}: {e}\")\n",
    "\n",
    "        elif isinstance(geom_data, list) and len(geom_data) >= 2:\n",
    "            # If not enough points for a polygon, store as LineString\n",
    "            coords = [(pt[\"lon\"], pt[\"lat\"]) for pt in geom_data]\n",
    "            try:\n",
    "                geometry_wkt = LineString(coords).wkt  # LineString WKT\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating linestring for SNA {element['id']}: {e}\")\n",
    "\n",
    "    # Build type field with sport and piste details\n",
    "    sport_type = tags.pop(\"sport\", \"skiing\")\n",
    "    piste_type = tags.pop(\"piste:type\", \"\")\n",
    "    full_type = f\"{sport_type}:{piste_type}\" if piste_type else sport_type\n",
    "\n",
    "    # Append to list\n",
    "    sna.append({\n",
    "        \"id\": f\"PA_id_{element['id']}\",\n",
    "        \"name\": tags.pop(\"name\", \"\"),\n",
    "        \"latitude\": element.get(\"lat\") if element[\"type\"] == \"node\" else None,\n",
    "        \"longitude\": element.get(\"lon\") if element[\"type\"] == \"node\" else None,\n",
    "        \"bounds\": element.get(\"bounds\", \"\"),\n",
    "        \"geometry\": geometry_wkt,  # Store WKT format\n",
    "        \"type\": full_type,\n",
    "        \"details\": tags,  # Remaining tags\n",
    "    })\n",
    "\n",
    "sna_df = pd.DataFrame(sna)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "sna_df.to_csv(\"./processed_data/skiing_and_winter_sports.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waterfall and Spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./raw_data/waterfall_and_spring.geojson', \"r\") as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize list for skiing & piste areas\n",
    "was = []\n",
    "\n",
    "# Process each element in the JSON data\n",
    "for element in data[\"elements\"]:\n",
    "    tags = element.get(\"tags\", {}).copy()  # Copy tags to avoid modifying original\n",
    "\n",
    "    geometry_wkt = None  # Default empty geometry\n",
    "\n",
    "    if element[\"type\"] == \"node\":\n",
    "        # Nodes: Represented as Points\n",
    "        lat = element.get(\"lat\")\n",
    "        lon = element.get(\"lon\")\n",
    "        if lat and lon:\n",
    "            geometry_wkt = Point(lon, lat).wkt\n",
    "\n",
    "    elif element[\"type\"] in [\"way\", \"relation\"]:\n",
    "        # Ways/Relations: Convert geometry list to Polygon (or LineString)\n",
    "        geom_data = element.get(\"geometry\", [])\n",
    "        if isinstance(geom_data, list) and len(geom_data) >= 3:\n",
    "            coords = [(pt[\"lon\"], pt[\"lat\"]) for pt in geom_data]\n",
    "            # Ensure it forms a closed polygon\n",
    "            if coords[0] != coords[-1]:\n",
    "                coords.append(coords[0])\n",
    "            try:\n",
    "                geometry_wkt = Polygon(coords).wkt  # Polygon WKT\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating polygon for WAS {element['id']}: {e}\")\n",
    "\n",
    "        elif isinstance(geom_data, list) and len(geom_data) >= 2:\n",
    "            # If not enough points for a polygon, store as LineString\n",
    "            coords = [(pt[\"lon\"], pt[\"lat\"]) for pt in geom_data]\n",
    "            try:\n",
    "                geometry_wkt = LineString(coords).wkt  # LineString WKT\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating linestring for WAS {element['id']}: {e}\")\n",
    "\n",
    "    # Build type field with sport and piste details\n",
    "    sport_type = tags.pop(\"sport\", \"skiing\")\n",
    "    piste_type = tags.pop(\"piste:type\", \"\")\n",
    "    full_type = f\"{sport_type}:{piste_type}\" if piste_type else sport_type\n",
    "\n",
    "    # Append to list\n",
    "    was.append({\n",
    "        \"id\": f\"PA_id_{element['id']}\",\n",
    "        \"name\": tags.pop(\"name\", \"\"),\n",
    "        \"latitude\": element.get(\"lat\") if element[\"type\"] == \"node\" else None,\n",
    "        \"longitude\": element.get(\"lon\") if element[\"type\"] == \"node\" else None,\n",
    "        \"bounds\": element.get(\"bounds\", \"\"),\n",
    "        \"geometry\": geometry_wkt,  # Store WKT format\n",
    "        \"type\": full_type,\n",
    "        \"details\": tags,  # Remaining tags\n",
    "    })\n",
    "\n",
    "was_df = pd.DataFrame(was)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>bounds</th>\n",
       "      <th>geometry</th>\n",
       "      <th>type</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PA_id_182981020</td>\n",
       "      <td>Sorgente del Brenta</td>\n",
       "      <td>46.007568</td>\n",
       "      <td>11.265688</td>\n",
       "      <td></td>\n",
       "      <td>POINT (11.2656884 46.0075682)</td>\n",
       "      <td>skiing</td>\n",
       "      <td>{'drinking_water': 'no', 'natural': 'spring'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PA_id_270176737</td>\n",
       "      <td></td>\n",
       "      <td>45.880423</td>\n",
       "      <td>10.824290</td>\n",
       "      <td></td>\n",
       "      <td>POINT (10.8242897 45.8804228)</td>\n",
       "      <td>skiing</td>\n",
       "      <td>{'drinking_water': 'yes', 'ele': '1116', 'natu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PA_id_287670802</td>\n",
       "      <td></td>\n",
       "      <td>46.255300</td>\n",
       "      <td>11.666197</td>\n",
       "      <td></td>\n",
       "      <td>POINT (11.6661973 46.2552996)</td>\n",
       "      <td>skiing</td>\n",
       "      <td>{'amenity': 'drinking_water', 'natural': 'spri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PA_id_316143276</td>\n",
       "      <td>Sorgente del Pra</td>\n",
       "      <td>45.855293</td>\n",
       "      <td>11.048271</td>\n",
       "      <td></td>\n",
       "      <td>POINT (11.0482711 45.8552932)</td>\n",
       "      <td>skiing</td>\n",
       "      <td>{'natural': 'spring'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PA_id_395572833</td>\n",
       "      <td></td>\n",
       "      <td>45.838584</td>\n",
       "      <td>10.808420</td>\n",
       "      <td></td>\n",
       "      <td>POINT (10.8084198 45.8385841)</td>\n",
       "      <td>skiing</td>\n",
       "      <td>{'amenity': 'drinking_water', 'natural': 'spri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                 name   latitude  longitude bounds  \\\n",
       "0  PA_id_182981020  Sorgente del Brenta  46.007568  11.265688          \n",
       "1  PA_id_270176737                       45.880423  10.824290          \n",
       "2  PA_id_287670802                       46.255300  11.666197          \n",
       "3  PA_id_316143276     Sorgente del Pra  45.855293  11.048271          \n",
       "4  PA_id_395572833                       45.838584  10.808420          \n",
       "\n",
       "                        geometry    type  \\\n",
       "0  POINT (11.2656884 46.0075682)  skiing   \n",
       "1  POINT (10.8242897 45.8804228)  skiing   \n",
       "2  POINT (11.6661973 46.2552996)  skiing   \n",
       "3  POINT (11.0482711 45.8552932)  skiing   \n",
       "4  POINT (10.8084198 45.8385841)  skiing   \n",
       "\n",
       "                                             details  \n",
       "0      {'drinking_water': 'no', 'natural': 'spring'}  \n",
       "1  {'drinking_water': 'yes', 'ele': '1116', 'natu...  \n",
       "2  {'amenity': 'drinking_water', 'natural': 'spri...  \n",
       "3                              {'natural': 'spring'}  \n",
       "4  {'amenity': 'drinking_water', 'natural': 'spri...  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "was_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "sna_df.to_csv(\"./processed_data/waterfall_and_spring.csv\", index=False, sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kge_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
